{
 "cells": [
  {
   "cell_type": "code",
   "id": "0315d5b0-6904-40a4-9538-6315b70bb9c7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def lista_dfs(ensayo_dict):\n",
    "    ensayos_dfs = []\n",
    "    for sujeto in ensayo_dict.keys():\n",
    "        ensayos_dfs.append(ensayo_dict[sujeto])\n",
    "    return ensayos_dfs\n",
    "\n",
    "# Filtrado de matrices\n",
    "def capsula(lista_dfs, th, porcentaje_):\n",
    "    # Conjuntamos las matrices\n",
    "    stack = np.stack([df.values for df in lista_dfs])\n",
    "    # Aplicamos filtro a cada matriz\n",
    "    above = stack > th\n",
    "\n",
    "    N = len(lista_dfs) # = 109\n",
    "    count_above = above.sum(axis=0) # Contando cuantos valores superan el umbral en celda\n",
    "\n",
    "    min_requerido = int(np.ceil(porcentaje_*N)) # 0.6*109 = 65.4\n",
    "    # con esto bastara con quedarnos con las celdas de 'above' que cumplan con min_requerido\n",
    "    # para así tener el número de sujetos que superan el umbral\n",
    "    result_bool = count_above >= min_requerido\n",
    "\n",
    "    result_df = pd.DataFrame(result_bool,\n",
    "                             index=lista_dfs[0].index,\n",
    "                             columns=lista_dfs[0].columns).astype(int)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "#metricas grafo\n",
    "def metricas_grafo(G):\n",
    "    # Métricas:\n",
    "    #Clusterin promedio\n",
    "    clust_coeff = nx.average_clustering(G)\n",
    "    # Longitud de camino promedio (camino más corto)\n",
    "    try:\n",
    "        path_length = nx.average_shortest_path_length(G)\n",
    "    except nx.NetworkXError:\n",
    "        path_length = np.nan # red no conexa\n",
    "    # Coeficiente de mundo pequeño\n",
    "    # Comparar con grafo aleatorio de igual N, K\n",
    "    G_rand = nx.gnm_random_graph(n=G.number_of_nodes(), m=G.number_of_edges())\n",
    "    clust_rand = nx.average_clustering(G_rand)\n",
    "    path_rand = nx.average_shortest_path_length(G_rand)\n",
    "    small_world_sigma = (clust_coeff / clust_rand) / (path_length / path_rand)\n",
    "    # Modularidad\n",
    "    from networkx.algorithms import community\n",
    "    communities = community.greedy_modularity_communities(G)\n",
    "    modularity = community.modularity(G, communities)\n",
    "    # Hubs\n",
    "    degree_dict = dict(G.degree())\n",
    "    betwenness = nx.betweenness_centrality(G)\n",
    "    betwenness = sorted(betwenness.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Eficiencia global y local\n",
    "    global_eff = nx.global_efficiency(G)\n",
    "    local_eff = nx.local_efficiency(G)\n",
    "\n",
    "    return (clust_coeff, path_length, small_world_sigma, communities,\n",
    "            modularity, betwenness, global_eff, local_eff, degree_dict)\n",
    "\n",
    "#grafo 2d\n",
    "def \tgrafo2D(df, pos):\n",
    "\tensayo_grafo = nx.from_pandas_adjacency(df)\n",
    "\tnx.draw_circular(ensayo_grafo, with_labels=True, font_size=7)\n",
    "\n",
    "\treturn ensayo_grafo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grafo3D(coords, Hub, pos):\n",
    "    x, y, z = coords['x'].values, coords['y'].values, coords['z'].values\n",
    "\n",
    "    nodes_size = [30 if idx != Hub[0] else 200 for idx in coords.index]\n",
    "    pos.scatter(x, y, z, alpha=0.5, s=nodes_size)\n",
    "    for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "        pos.text(x_, y_, z_, coords.index[idx], fontsize=5)\n",
    "        if coords.index[idx] == Hub[0]:\n",
    "            pos.text(x_, y_, z_, 'HUB', color='red', fontweight='bold', fontsize=10)\n",
    "\n",
    "def grafo_comunidades(comunidades, Hub, coords, pos):\n",
    "    x, y, z = coords['x'].values, coords['y'].values, coords['z'].values\n",
    "\n",
    "    nodes_size = [30 if idx != Hub[0] else 200 for idx in coords.index]\n",
    "    pos.scatter(x, y, z, alpha=0.5, s=nodes_size)\n",
    "    for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "        pos.text(x_, y_, z_, coords.index[idx], fontsize=5)\n",
    "        if coords.index[idx] == Hub[0]:\n",
    "            pos.text(x_, y_, z_, 'HUB', color='red', fontweight='bold', fontsize=10)\n",
    "\n",
    "    colores = ['red', 'green', 'blue', 'black', 'orange']\n",
    "    for n_comunidad, comunidad in enumerate(comunidades):\n",
    "        for idx in range(len(comunidad)-1):\n",
    "            n1, n2 = list(comunidad)[idx], list(comunidad)[idx+1]\n",
    "            x_ = [coords.loc[n1, 'x'], coords.loc[n2, 'x']]\n",
    "            y_ = [coords.loc[n1, 'y'], coords.loc[n2, 'y']]\n",
    "            z_ = [coords.loc[n1, 'z'], coords.loc[n2, 'z']]\n",
    "            pos.plot(x_, y_, z_, linewidth=3, alpha=0.4, color=colores[n_comunidad])\n",
    "    pos.set_title('comunidades ensayo ')\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mi_modulo'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m stats\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmi_modulo\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'mi_modulo'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "44b77f43-0ebd-4104-a9e7-02dcfdfab2dc",
   "metadata": {},
   "source": [
    "\n",
    "ensayo3_excel = r\"C:\\Users\\admin\\OneDrive\\Documentos\\GitHub\\Neurociencias-2026-1\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_03.xlsx\"\n",
    "ensayo4_excel = r\"C:\\Users\\admin\\OneDrive\\Documentos\\GitHub\\Neurociencias-2026-1\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_04.xlsx\"\n",
    "ensayo5_excel = r\"C:\\Users\\admin\\OneDrive\\Documentos\\GitHub\\Neurociencias-2026-1\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_05.xlsx\"\n",
    "ensayo6_excel = r\"C:\\Users\\admin\\OneDrive\\Documentos\\GitHub\\Neurociencias-2026-1\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_06.xlsx\"\n",
    "coordenadas_csv = r\"C:\\Users\\admin\\OneDrive\\Documentos\\GitHub\\Neurociencias-2026-1\\Neurociencias-2026-1\\S03_datasets\\MI_coordinates.csv\"\n",
    "\n",
    "\n",
    "ensayo3_dict = pd.read_excel(ensayo3_excel, sheet_name=None, index_col=0)\n",
    "ensayo4_dict = pd.read_excel(ensayo4_excel, sheet_name=None, index_col=0)\n",
    "ensayo5_dict = pd.read_excel(ensayo5_excel, sheet_name=None, index_col=0)\n",
    "ensayo6_dict = pd.read_excel(ensayo6_excel, sheet_name=None, index_col=0)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "970e731c-801e-4059-8993-185938b42dd1",
   "metadata": {},
   "source": [
    "\n",
    "ensayos3_dfs = lista_dfs(ensayo3_dict)\n",
    "ensayos4_dfs = lista_dfs(ensayo4_dict)\n",
    "ensayos5_dfs = lista_dfs(ensayo5_dict)\n",
    "ensayos6_dfs = lista_dfs(ensayo6_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "th25, th50, th75, promedio, varianza = [], [], [], [], []\n",
    "mu_sigma = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7))\n",
    "for sujeto in ensayos4_dfs:\n",
    "    # Calculo de estadísticos\n",
    "    data = sujeto.stack().values\n",
    "    th25.append(np.percentile(data, 25))\n",
    "    th50.append(np.percentile(data, 50))\n",
    "    th75.append(np.percentile(data, 75))\n",
    "    promedio.append(np.mean(data))\n",
    "    varianza.append(np.var(data))\n",
    "    mu_sigma.append(np.mean(data) + np.var(data))\n",
    "    # Plots\n",
    "    sns.histplot(sujeto.stack().values, ax=axes[0][0], kde=True)\n",
    "    sns.ecdfplot(sujeto.stack().values, ax=axes[0][1])\n",
    "axes[1][0].plot(th25, label='Percentil al 25%')\n",
    "axes[1][0].plot(th50, label='Percentil al 50%')\n",
    "axes[1][0].plot(th75, label='Percentil al 75%')\n",
    "axes[1][0].plot(promedio, label='Media')\n",
    "axes[1][0].plot(varianza, label='Varianza')\n",
    "axes[1][0].plot(mu_sigma, label='mu+sigma')\n",
    "axes[1][0].legend()\n",
    "\n",
    "estadisticos_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'],\n",
    "                               index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "columnas = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "min_, max_, mediana_, cosa_ = [], [], [], []\n",
    "for columna in columnas:\n",
    "    d1, d2, d3, d4 = np.min(columna), np.max(columna), np.median(columna), stats.median_abs_deviation(columna)\n",
    "    min_.append(d1)\n",
    "    max_.append(d2)\n",
    "    mediana_.append(d3)\n",
    "    cosa_.append(d4)\n",
    "estadisticos_df.loc['min'] = min_\n",
    "estadisticos_df.loc['max'] = max_\n",
    "estadisticos_df.loc['mediana'] = mediana_\n",
    "estadisticos_df.loc['cosa_rara'] = cosa_\n",
    "test_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'],\n",
    "                       index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "estadisticos_ = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "for idx, columna in enumerate(test_df.columns):\n",
    "    test_df[columna] = [np.min(estadisticos_[idx]), np.max(estadisticos_[idx]),\n",
    "                        np.median(estadisticos_[idx]), stats.median_abs_deviation(estadisticos_[idx])]\n",
    "\n",
    "display(test_df)"
   ],
   "id": "4f0259edd9fb5ac2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Lo que nos arrojan estos estadísticos: Primero la mediana nos dice que el 50% de las conexiones tienen una fuerza menor a 0.27, por o que la mayoria de las conexiones son ruido o demasiado debiles por lo que un umbral bajo debería entrar ese ruido. Pero el percentil 75 nos dice que el 25% de las conexiones más fuertes empezaban a partir de 0.48 por lo que un umbral de 5 deberia considerar estas conexiones",
   "id": "758ad699e3b56d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "th25, th50, th75, promedio, varianza = [], [], [], [], []\n",
    "mu_sigma = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7))\n",
    "for sujeto in ensayos4_dfs:\n",
    "    # Calculo de estadísticos\n",
    "    data = sujeto.stack().values\n",
    "    th25.append(np.percentile(data, 25))\n",
    "    th50.append(np.percentile(data, 50))\n",
    "    th75.append(np.percentile(data, 75))\n",
    "    promedio.append(np.mean(data))\n",
    "    varianza.append(np.var(data))\n",
    "    mu_sigma.append(np.mean(data) + np.var(data))\n",
    "    # Plots\n",
    "    sns.histplot(sujeto.stack().values, ax=axes[0][0], kde=True)\n",
    "    sns.ecdfplot(sujeto.stack().values, ax=axes[0][1])\n",
    "axes[1][0].plot(th25, label='Percentil al 25%')\n",
    "axes[1][0].plot(th50, label='Percentil al 50%')\n",
    "axes[1][0].plot(th75, label='Percentil al 75%')\n",
    "axes[1][0].plot(promedio, label='Media')\n",
    "axes[1][0].plot(varianza, label='Varianza')\n",
    "axes[1][0].plot(mu_sigma, label='mu+sigma')\n",
    "axes[1][0].legend()\n",
    "\n",
    "estadisticos_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'],\n",
    "                               index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "columnas = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "min_, max_, mediana_, cosa_ = [], [], [], []\n",
    "for columna in columnas:\n",
    "    d1, d2, d3, d4 = np.min(columna), np.max(columna), np.median(columna), stats.median_abs_deviation(columna)\n",
    "    min_.append(d1)\n",
    "    max_.append(d2)\n",
    "    mediana_.append(d3)\n",
    "    cosa_.append(d4)\n",
    "estadisticos_df.loc['min'] = min_\n",
    "estadisticos_df.loc['max'] = max_\n",
    "estadisticos_df.loc['mediana'] = mediana_\n",
    "estadisticos_df.loc['cosa_rara'] = cosa_\n",
    "test_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'],\n",
    "                       index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "estadisticos_ = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "for idx, columna in enumerate(test_df.columns):\n",
    "    test_df[columna] = [np.min(estadisticos_[idx]), np.max(estadisticos_[idx]),\n",
    "                        np.median(estadisticos_[idx]), stats.median_abs_deviation(estadisticos_[idx])]\n",
    "\n",
    "display(test_df)\n"
   ],
   "id": "c4855e5f594ed77f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Estas estadísticas son reforzantes a la conclusión del umbral, ya que el percentil 75 se mantiene en 0.48 por lo que un umbral de 5 está bien",
   "id": "7b5032bcfc82a643",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# El siguiente rango de umbrales me ayudará a decidir cuál utilizar\n",
    "rango_umbrales = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "# El umbral de la población está al 60 para mantener una base solida de datos\n",
    "th_poblacion = 0.6\n",
    "barridoumbrales = []\n",
    "\n",
    "lista3 = ensayos3_dfs\n",
    "\n",
    "for th in rango_umbrales:\n",
    "    try:\n",
    "        df_resultado = capsula(lista3, th, th_poblacion)\n",
    "\n",
    "        grafoumbral = nx.from_pandas_adjacency(df_resultado)\n",
    "\n",
    "        numnodos = grafoumbral.number_of_nodes()\n",
    "        numar = grafoumbral.number_of_edges()\n",
    "        densidad = nx.density(grafoumbral)\n",
    "\n",
    "        conectados = nx.is_connected(grafoumbral)\n",
    "        numcomp = nx.number_connected_components(grafoumbral)\n",
    "\n",
    "        barridoumbrales.append({\n",
    "            'Umbral': th,\n",
    "            'Nodos': numnodos,\n",
    "            'Aristas': numar,\n",
    "            'Densidad': round(densidad, 3),\n",
    "            'Conectado': conectados,\n",
    "            'Componentes': numcomp\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error {th}: {e}\")\n",
    "\n",
    "# En esta tabla imprimo los resultados de la investigación de umbrales para visualizar mejor qué umbrales son mejores\n",
    "tablaumbrales3 = pd.DataFrame(barridoumbrales)\n",
    "tablaumbrales3.set_index('Umbral', inplace=True)\n",
    "\n",
    "display(tablaumbrales3)"
   ],
   "id": "e7821e969dfd6ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#las cosas más importantes de la tabla son: densidad, ya que buscamos una densidad del 15 al 30%, asi que buscamos un .25 aprox, no podemos tener muchos componentes porque significa que el umbral esta tan alto, que segmenta o secciona regiones\n",
    "\n",
    "# por esta razón mi umbral debe ser 5 para ensayo 3, elimina las conexiones débiles pero aún mantiene suficiente de la red"
   ],
   "id": "c12d2135d0ecf3bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# El siguiente rango de umbrales me ayudará a decidir cuál utilizar\n",
    "rango_umbrales = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "# El umbral de la población está al 60 para mantener una base solida de datos\n",
    "th_poblacion = 0.6\n",
    "barridoumbrales = []\n",
    "\n",
    "lista6 = ensayos6_dfs\n",
    "\n",
    "for th in rango_umbrales:\n",
    "    try:\n",
    "        df_resultado = capsula(lista6, th, th_poblacion)\n",
    "\n",
    "        grafoumbral = nx.from_pandas_adjacency(df_resultado)\n",
    "\n",
    "        numnodos = grafoumbral.number_of_nodes()\n",
    "        numar = grafoumbral.number_of_edges()\n",
    "        densidad = nx.density(grafoumbral)\n",
    "\n",
    "        conectados = nx.is_connected(grafoumbral)\n",
    "        numcomp = nx.number_connected_components(grafoumbral)\n",
    "\n",
    "        barridoumbrales.append({\n",
    "            'Umbral': th,\n",
    "            'Nodos': numnodos,\n",
    "            'Aristas': numar,\n",
    "            'Densidad': round(densidad, 3),\n",
    "            'Conectado': conectados,\n",
    "            'Componentes': numcomp\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando umbral {th}: {e}\")\n",
    "\n",
    "# En esta tabla imprimo los resultados de la investigación de umbrales para visualizar mejor qué umbrales son mejores\n",
    "tablaumbrales6 = pd.DataFrame(barridoumbrales)\n",
    "tablaumbrales6.set_index('Umbral', inplace=True)\n",
    "\n",
    "display(tablaumbrales6)"
   ],
   "id": "d5a37f5e3e85fc28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# A pesar de que corrí esta tabla para ensayos 4,5,6, dejo unicamente la de 6 para demostrar que el umbral se mantiene para todos los ensayos",
   "id": "f8021a9925a2a2bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "597e621a-9b30-47de-a8a7-807ff8cf7496",
   "metadata": {},
   "source": [
    "#Aqui solo creamos los df filtrados con el umbral 5 y poblacion al 60%\n",
    "resultado3_df = capsula(ensayos3_dfs, 0.5, 0.6)\n",
    "resultado4_df = capsula(ensayos4_dfs, 0.5, 0.6)\n",
    "resultado5_df = capsula(ensayos5_dfs, 0.5, 0.6)\n",
    "resultado6_df = capsula(ensayos6_dfs, 0.5, 0.6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Aquí visualizaré las matrices de adyacencia de los 4 ensayos para ver diferencias\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Primero analizaré las manos, pero en azul estara el movimiento real y en rojo el imaginario, lo mismo para los pies\n",
    "\n",
    "sns.heatmap(resultado3_df, ax=axes[0, 0], cbar=False, cmap=\"Blues\")\n",
    "axes[0, 0].set_title(\"Movimiento de manos\")\n",
    "axes[0, 0].set_ylabel(\"Canales EEG\")\n",
    "\n",
    "sns.heatmap(resultado4_df, ax=axes[0, 1], cbar=False, cmap=\"Reds\")\n",
    "axes[0, 1].set_title(\"Imaginación de manos\")\n",
    "\n",
    "sns.heatmap(resultado5_df, ax=axes[1, 0], cbar=False, cmap=\"Blues\")\n",
    "axes[1, 0].set_title(\"Movimiento de pies\")\n",
    "axes[1, 0].set_ylabel(\"Canales EEG\")\n",
    "\n",
    "sns.heatmap(resultado6_df, ax=axes[1, 1], cbar=False,cmap=\"Reds\")\n",
    "axes[1, 1].set_title(\"Imaginación de pies\")\n",
    "\n",
    "plt.suptitle(f\"Comparacion de Mat de Ady (El umbral es de: {0.5} | Porcentaje de la población: {0.6*100}%)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "20ddf1e194111582",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# En la comparación de manos y pies: real e imaginario, podemos observar algunas zonas activas (que vemos aqui como puntos pequeños) que se encuentran en la corteza motora primaria en zonas frontotemporales, esto hace sentido ya que son las áreas de movimiento y por eso los vemos activos en el movimiento real, en manos imaginario no lo vemos activo lo que da sustento a que sí hay una diferencia entre hacer un movimiento y solo imaginarlo, en los pies no se nota mucho la diferencia, esto, de nuevo, porque la representación de los pies es profunda en la corteza, pero lo veremos con los estadísticos\n",
    "\n",
    "#Pero se escogió un umbral bueno ya que vemos la moludaridad del cerebro que se conservan en ambos movimientos \"reales e imaginarios\""
   ],
   "id": "a8edd8edaf080a46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ensayo3_grafo_ = nx.from_pandas_adjacency(resultado3_df)\n",
    "ensayo4_grafo_ = nx.from_pandas_adjacency(resultado4_df)\n",
    "ensayo5_grafo_ = nx.from_pandas_adjacency(resultado5_df)\n",
    "ensayo6_grafo_ = nx.from_pandas_adjacency(resultado6_df)\n",
    "\n",
    "(clust_coeff_3, path_length_3, small_world_sigma_3, communities_3,\n",
    " modularity_3, betwenness_3, global_eff_3, local_eff_3, degree_dict_3) = metricas_grafo(ensayo3_grafo_)\n",
    "\n",
    "(clust_coeff_4, path_length_4, small_world_sigma_4, communities_4,\n",
    " modularity_4, betwenness_4, global_eff_4, local_eff_4, degree_dict_4 ) = metricas_grafo(ensayo4_grafo_)\n",
    "\n",
    "(clust_coeff_5, path_length_5, small_world_sigma_5, communities_5,\n",
    " modularity_5, betwenness_5, global_eff_5, local_eff_5, degree_dict_5) = metricas_grafo(ensayo5_grafo_)\n",
    "\n",
    "(clust_coeff_6, path_length_6, small_world_sigma_6, communities_6,\n",
    " modularity_6, betwenness_6, global_eff_6, local_eff_6, degree_dict_6 ) = metricas_grafo(ensayo6_grafo_)\n",
    "\n",
    "print(f\"--- ANÁLISIS MANOS (Umbral {.5}) ---\")\n",
    "print(f\"Métrica            | Real (E3) | Imaginado (E4) | Diferencia\")\n",
    "print(f\"-------------------|-----------|----------------|-----------\")\n",
    "print(f\"Eficiencia Global  | {global_eff_3:.4f}    | {global_eff_4:.4f}         | {global_eff_3 - global_eff_4:.4f}\")\n",
    "print(f\"Eficiencia Local   | {local_eff_3:.4f}    | {local_eff_4:.4f}         | {local_eff_3 - local_eff_4:.4f}\")\n",
    "print(f\"Clustering Coeff   | {clust_coeff_3:.4f}    | {clust_coeff_4:.4f}         | {clust_coeff_3 - clust_coeff_4:.4f}\")\n",
    "print(f\"Small-World Sigma  | {small_world_sigma_3:.4f}    | {small_world_sigma_4:.4f}         | {small_world_sigma_3 - small_world_sigma_4:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"--- ANÁLISIS PIES (Umbral {.5}) ---\")\n",
    "print(f\"Métrica            | Real (E5) | Imaginado (E6) | Diferencia\")\n",
    "print(f\"-------------------|-----------|----------------|-----------\")\n",
    "print(f\"Eficiencia Global  | {global_eff_5:.4f}    | {global_eff_6:.4f}         | {global_eff_5 - global_eff_6:.4f}\")\n",
    "print(f\"Eficiencia Local   | {local_eff_5:.4f}    | {local_eff_6:.4f}         | {local_eff_5 - local_eff_6:.4f}\")\n",
    "print(f\"Clustering Coeff   | {clust_coeff_5:.4f}    | {clust_coeff_6:.4f}         | {clust_coeff_5 - clust_coeff_6:.4f}\")\n",
    "print(f\"Small-World Sigma  | {small_world_sigma_5:.4f}    | {small_world_sigma_6:.4f}         | {small_world_sigma_5 - small_world_sigma_6:.4f}\")\n"
   ],
   "id": "d5c6ba4050f2a7a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imprimí la tabla para poder recordar para qué me servían algunos datos, utilicé inteligencia artificial para el código que genera la tabla y se viera más organizada\n",
    "# Aqui podemos ver que la eficiencia global, que es mayor en la real que en la imaginaria, lo que significa que cuando se mueven las manos realmente la red es más rápida y directa. En cambio, cuando se imagina el movimiento la red integra menos, mi suposición es que se debe a la falta de activación de neuronas corticales para el movimiento motor en manos. El clustering tambien nos muestra que la imaginación de movimiento es menos especializada localmente, esto lo atribuyo a la misma falta de activación específica para movimiento de músculos agonistas y relajación de músculos antagonistas. Al ser imaginario, se activan ciertas áreas cercanas al movimiento, tal vez en preparación al movimiento real, pero no generan una especialización local al no mover músculos específicos y refinar esos movimientos.\n",
    "\n",
    "# Todas estas inferencias se hacen basandose en las manos, pero en los pies podemos ver una diferencia entre las redes muy pequeña, como se vio en las matrices, esto, como lo mencioné antes, me imagino que se debe a que la representacion motora en el Homúnculo de los pies en la corteza se encuentra en la cisura interhemisférica, es una cisura profunda que puede dificultar la lectura por un electrodo de EEG, aunque no puedo descartar que la diferencia de esfuerzo entre motor e imaginario sea indiferenciable para el umbral\n",
    "\n",
    "#quiero destacar que en sigma aparece como Nan porqeu la red no es sun solo bloque, en el umbral podíamos distingir 7 componentes, por lo que no podemos buscar el camino mas corto entre componentes que no estan conectados"
   ],
   "id": "4e313c9d575f5d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "eeg_coords = pd.read_csv(coordenadas_csv)\n",
    "eeg_coords.set_index(\"canal\", drop=True, inplace=True)"
   ],
   "id": "852df11dcc5456cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "tareas = [\n",
    "    (\"Ensayo 3\", ensayos3_dfs),\n",
    "    (\"Ensayo 4\", ensayos4_dfs),\n",
    "    (\"Ensayo 5\", ensayos5_dfs),\n",
    "    (\"Ensayo 6 \", ensayos6_dfs)\n",
    "]\n",
    "for nombre, datos_sujetos in tareas:\n",
    "\n",
    "    df_resultado = capsula(datos_sujetos, 0.5, 0.6)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plt.sca(ax)\n",
    "\n",
    "    grafo = grafo2D(df_resultado, ax)\n",
    "    ax.set_title(f\"{nombre}\", fontsize=14)\n",
    "\n",
    "    (clust, path, sigma, coms, mod, betw, eff_g, eff_l, deg) = metricas_grafo(grafo)\n",
    "    hub_info = betw[0]\n",
    "\n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(f\" > Eficiencia Global: {eff_g:.4f}\")\n",
    "    print(f\" > Clustering: {clust:.4f}\")\n",
    "    print(f\" > Modularidad: {mod:.4f}\")\n",
    "    print(f\" > Hub Principal: {hub_info[0]} ({hub_info[1]:.3f})\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    plt.show()"
   ],
   "id": "fbf97f7f388cead5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Primero notamos que el HUB es Afz, un nodo que lejos de encontrarse en cortezas motora, se encuentra en la linea media frontal que se encarga de atención ejecutiva, toma de decisiones y planificación lo cual es consistente por el tipo de ejercicio, ya que todos los ensayos requieren de planificación de movimientos (aunque sean imaginarios) por el esfuerzo cognitivo que se requiere para mantener la atención. Esto se mantiene consistente con ambos ejercicios ya que se activa en ambos estados\n",
    "# Sin embargo la eficiencia global sigue cayendo cuanso cambiamos de motor a imaginario porque requiere menos esfuerzo que a motora\n",
    "#Aparte los grafos 2D se ven muy parecidos porque las diferencias son funcionales y algo sutiles, no es anatomica, por eso se ven tan parecidos."
   ],
   "id": "154e1a1395e64db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for nombre, datos_sujetos in tareas:\n",
    "\n",
    "    df_resultado = capsula(datos_sujetos, 0.5, 0.6)\n",
    "    grafohub = nx.from_pandas_adjacency(df_resultado)\n",
    "\n",
    "    metricas = metricas_grafo(grafohub)\n",
    "    betweenness = metricas[5]\n",
    "    hub_info = betweenness[0]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "    grafo3D(eeg_coords, hub_info, ax)\n",
    "\n",
    "    ax.set_title(f\"HUB 3D: {nombre}\\nElectrodo: {hub_info[0]}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "683571c5a62fef75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Esto solo confirma lo del HUB siendo el punto principal funcional, por lo que todo el ejercicio se guia por un área de control de la atencion y control ejecutivo de desiciones, más que algo motor",
   "id": "f5f0e5b65ada1ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for nombre, datos_sujetos in tareas:\n",
    "\n",
    "    df_resultado = capsula(datos_sujetos, 0.5, 0.6)\n",
    "    grafocom = nx.from_pandas_adjacency(df_resultado)\n",
    "\n",
    "    metricas = metricas_grafo(grafocom)\n",
    "    comunidades = metricas[3]\n",
    "    betweenness = metricas[5]\n",
    "    hub_info = betweenness[0]\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "    grafo_comunidades(comunidades, hub_info, eeg_coords, ax)\n",
    "\n",
    "    ax.set_title(f\"Comunidad de: {nombre}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "10f1b30c51a97cad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# No veo la necesidad de realizar más observaciones o analisis, ya que a lo largo de este script he ido desmenusando las diferencias entre ejercicios motores e imaginarios, aparte algunas diferencias entre pies y manos, por lo que conlcuiré con los analisis de los grafos 3D.\n",
    "# Iniciaremos con el analisis de los colores, primero vemos modulos rojos en areas forntales centrales, esto es porque es un módulo ejecutivo motor, como lo he mencionado antes se encarga de planificar y ejecutar la acción\n",
    "# Tenemos otra comunidad en las areas parietales occipitales, que es la parte trasera, estas areas procesan la informacion sensorial y visual porque los sujetos debian observar un estímulo visual, estos modulos se presentan constantes en los diferentes ensayos, auqnue pueden cambiar la intensidad pero nos explica la conectividad entre áreas durante los ensayos\n",
    "\n",
    "# Muchas de esas conexiones salen de Afz que es constante a lo descrito previamente, ya que si el HUB hubiera estado en otras áreas como C3 y C4 que son controles motores serian conexiones locales, por lo que el cerebro o sus conexiones están centralizadas en el control de tareas\n",
    "\n",
    "#Ahora comparando entre ensayo motor de manos e imaginario de manos, las lineas rojas y azules en el ensayo 3, que representan la conexion entre la parte frontal con la parte trasera, estas conexiones se ven mas densas y solidas en el ensayo 3, a diferencia del 4 que es imaginario, donde estas conexiones son menos densas , por lo que vemos la baja de eficiencia global\n",
    "\n",
    "# Una conclusión desde las neurociencias podemos observar que las tareas imaginadas, como lo son el ensayo 4 y 6 demuestran que imaginar movimientos, no es un proceso aislado, ya que activa los mismos circuitos funcionales que un movimiento real (ensayos 3 y 5)"
   ],
   "id": "9a9a9ce4606723e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
