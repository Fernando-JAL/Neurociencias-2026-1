{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e761df69-3ea9-443e-88c6-87ced0d3f9df",
   "metadata": {},
   "source": [
    "# Examen del 2do Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac53475-ca81-4a07-82e5-20e01a1787f0",
   "metadata": {},
   "source": [
    "1. Utilizando el dataset de _Coactivation_matrix.mat_:\n",
    "- Calcule el coeficiente de mundo pequeño\n",
    "- Calcule las comunidades del grafo\n",
    "- Calcule los hub\n",
    "- Calcule la eficiencia global\n",
    "- Calcule la eficiencia local\n",
    "- Determine el grado de cada nodo\n",
    "\n",
    "2. Utilizando el dataset de _Coactivation_matrix.mat_:\n",
    "- Generar el mapa de calor de cada matriz de conectividad\n",
    "- Generar la distribución de datos de cada matriz de conectividad\n",
    "- ¿Qué valor se encuentra en el percentil 0.25, 0.5 y 0.75 de la matriz de conectividad?\n",
    "- Cree los 3 grafos 2D filtrando la matriz de conectividad con los valores dados por los percentiles del ejercicio anterior\n",
    "\n",
    "3. Utilizando el dataset de _Coactivation_matrix.mat_:\n",
    "- Genere el grafo 3D\n",
    "- Haga que el tamaño de nodos sea proporcional a su grado; es decir, q entre mayor sea su grado, mayor sea el tamaño del nodo ploteado\n",
    "- Haga que el color de las aristas este relacionado al valor de la matriz de conectividad. Utilizar el map color Hot\n",
    "\n",
    "4. Utilizando el dataset de _chb01_01.edf_:\n",
    "- Calcule el coeficiente de mundo pequeño\n",
    "- Calcule las comunidades del grafo\n",
    "- Calcule los hub\n",
    "- Calcule la eficiencia global\n",
    "- Calcule la eficiencia local\n",
    "- Determine el grado de cada nodo\n",
    "\n",
    "5. Utilizando el dataset de _chb01_01.edf_:\n",
    "- Genere el grafo 3D\n",
    "- Haga que el tamaño de nodos sea proporcional a su grado; es decir, q entre mayor sea su grado, mayor sea el tamaño del nodo ploteado\n",
    "- Haga que el color de las aristas este relacionado al valor de la matriz de conectividad. Utilizar el map color Hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c4de85-5489-4594-bf00-161c525d79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import networkx.algorithms.smallworld as sw\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import mne\n",
    "from scipy.signal import coherence, hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f24903-7f98-4ba1-b780-19617db1821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_ruta = r\"C:\\Users\\maria\\OneDrive\\Documentos\\MATLAB\\Coactivation_matrix.mat\"\n",
    "datos = scipy.io.loadmat(datos_ruta)\n",
    "data = datos[\"Coactivation_matrix\"]\n",
    "df = pd.DataFrame(data)\n",
    "df = df.fillna(0)\n",
    "G = nx.from_numpy_array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c660f688-02fb-4a85-88df-5246f8f8929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef cluster: 0.3844533292242755\n",
      "Ruta más corta: 2.2148737961545844\n",
      "Coef cluster (random): 0.09179016074376502\n",
      "Ruta más corta (random): 1.9123831833191438\n",
      "Coef mundo pequeño: 3.6163747362502545\n"
     ]
    }
   ],
   "source": [
    "C = nx.average_clustering(G)\n",
    "L = nx.average_shortest_path_length(G)\n",
    "C, L\n",
    "print(\"Coef cluster:\", C)\n",
    "print(\"Ruta más corta:\", L)\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "G_random = nx.gnm_random_graph(n_nodes, n_edges)\n",
    "clustering_coefficient_random = nx.average_clustering(G_random)\n",
    "print(\"Coef cluster (random):\", clustering_coefficient_random)\n",
    "if nx.is_connected(G_random):\n",
    "    avg_shortest_path_length_random = nx.average_shortest_path_length(G_random)\n",
    "    print(\"Ruta más corta (random):\", avg_shortest_path_length_random)\n",
    "if avg_shortest_path_length_random > 0 and L > 0:\n",
    "    small_world_coefficient = (C / clustering_coefficient_random) / (L / avg_shortest_path_length_random)\n",
    "    print(\"Coef mundo pequeño:\", small_world_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6ae4e-8de5-4c6f-8d51-a7ebab517db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "comunidades = list(community.greedy_modularity_communities(G))\n",
    "print(f\"Ncomunidades: {len(comunidades)}\")\n",
    "for i, c in enumerate(comunidades):\n",
    "    print(f\"Comunidad {i+1} ({len(c)} nodos): {sorted(list(c))[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3a9ed-5cc9-4cba-a82a-3c97682a7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "centralidad = nx.degree_centrality(G)\n",
    "print(\"hub centralidad\")\n",
    "C=sorted(centralidad.items(), key=lambda item: item[1], reverse=True)\n",
    "print(C[:10])\n",
    "intermediacion=nx.betweenness_centrality(G, weight='weight')\n",
    "print(\"\\n hub intermediación\")\n",
    "In=sorted(intermediacion.items(), key=lambda item: item[1], reverse=True)\n",
    "print(In[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e252be5-3d9c-4021-af5d-dc1ac9cedcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(G.degree())\n",
    "avg_degree = np.mean(list(degrees.values()))\n",
    "hubs = [node for node, degree in degrees.items() if degree > avg_degree]\n",
    "print(\"Hubs degree - average):\", hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41d5c6-ca57-44dc-8863-fe2952d5856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_efficiency(G):\n",
    "    n = len(G)\n",
    "    if n <= 1:\n",
    "        return 0\n",
    "    lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    s = 0\n",
    "    for u in lengths:\n",
    "        for v, d in lengths[u].items():\n",
    "            if u != v:\n",
    "                s += 1 / d\n",
    "    return s / (n * (n - 1))\n",
    "def local_efficiency(G):\n",
    "    effs = []\n",
    "    for v in G:\n",
    "        vecinos = list(G.neighbors(v))\n",
    "        if len(vecinos) >= 2:\n",
    "            sub = G.subgraph(vecinos)\n",
    "            effs.append(global_efficiency(sub))\n",
    "    return np.mean(effs)\n",
    "E_global = global_efficiency(G)\n",
    "E_local = local_efficiency(G)\n",
    "print(f\"Ef global: {E_global:.3f}\")\n",
    "print(f\"Ef local:  {E_local:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f228c7-9bad-4d28-9f4c-d91f78052a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree())\n",
    "degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93aa3a-8b76-44b4-b189-4d7b3d0827c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq_target = 256       \n",
    "fmin, fmax = 8, 13 \n",
    "corr_matrix = np.corrcoef(data)\n",
    "corr_df = pd.DataFrame(corr_matrix)\n",
    "n_channels=638\n",
    "coh_matrix = np.zeros((n_channels, n_channels))\n",
    "for i in range(n_channels):\n",
    "    for j in range(n_channels):\n",
    "        f, Cxy = coherence(data[i], data[j], fs=sfreq_target, nperseg=sfreq_target*2)\n",
    "        mask = (f >= fmin) & (f <= fmax)\n",
    "        coh_matrix[i, j] = np.mean(Cxy[mask])\n",
    "coh_df = pd.DataFrame(coh_matrix)\n",
    "analytic_signal = hilbert(data)\n",
    "phase_data = np.angle(analytic_signal)\n",
    "plv_matrix = np.zeros((n_channels, n_channels))\n",
    "for i in range(n_channels):\n",
    "    for j in range(n_channels):\n",
    "        phase_diff = phase_data[i] - phase_data[j]\n",
    "        plv_matrix[i, j] = np.abs(np.sum(np.exp(1j * phase_diff)) / phase_diff.size)\n",
    "plv_df = pd.DataFrame(plv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff6973-8d8b-4afd-8110-b70e5369c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "co= sns.heatmap(corr_df.values,\n",
    "                 annot=False, cmap='GnBu', fmt=\".2f\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "val_corr = corr_df.values[np.triu_indices_from(corr_df, k=1)]\n",
    "plt.hist(val_corr, bins=45)\n",
    "p25 = np.percentile(val_corr, 25)  \n",
    "p50 = np.percentile(val_corr, 50)  \n",
    "p75 = np.percentile(val_corr, 75)  \n",
    "print(f\"percentil 25: {p25:.4f}\")\n",
    "print(f\"percentil 50: {p50:.4f}\")\n",
    "print(f\"percentil 75: {p75:.4f}\")\n",
    "percentiles = {'25': p25, '50': p50, '75': p75}\n",
    "filtrado_p = {}\n",
    "for name, threshold in percentiles.items():\n",
    "    G_filt_p = nx.Graph()\n",
    "    num_nodes = corr_df.shape[0]\n",
    "    G_filt_p.add_nodes_from(range(num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            weight = corr_df.iloc[i, j]\n",
    "            if abs(weight) > threshold: \n",
    "                G_filt_p.add_edge(i, j, weight=weight)\n",
    "    graph_key = f\"pearson_{name.replace(' ', '_').lower()}\"\n",
    "    filtrado_p[graph_key] = G_filt_p\n",
    "    print(f\"Created graph '{graph_key}' with {G_filt_p.number_of_nodes()} nodes and {G_filt_p.number_of_edges()} edges.\")\n",
    "for graph_key, G_to_draw in filtrado_p.items():\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(G_to_draw) \n",
    "    nx.draw(G_to_draw, pos, with_labels=False, node_size=20, edge_color='gray', alpha=0.6)\n",
    "    plt.title(f'Filt Graph: {graph_key.replace(\"_\", \" \").title()}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c8bc7-2522-4c1c-8410-432f1ce55a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "coh = sns.heatmap(coh_df.values,\n",
    "                 annot=False, cmap='GnBu', fmt=\".2f\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "val_coh = corr_df.values[np.triu_indices_from(coh_df, k=1)]\n",
    "plt.hist(val_coh, bins=45)\n",
    "p25_c = np.percentile(val_coh, 25)  \n",
    "p50_c = np.percentile(val_coh, 50)  \n",
    "p75_c = np.percentile(val_coh, 75)  \n",
    "print(f\"Percentil 25: {p25_c:.4f}\")\n",
    "print(f\"Percentil 50: {p50_c:.4f}\")\n",
    "print(f\"Percentil 75: {p75_c:.4f}\")\n",
    "percentiles_c = {'25': p25_c, '50': p50_c, '75': p75_c}\n",
    "filtrado_c = {}\n",
    "for name, threshold in percentiles_c.items():\n",
    "    G_filt_c = nx.Graph()\n",
    "    num_nodes_c = coh_df.shape[0]\n",
    "    G_filt_c.add_nodes_from(range(num_nodes_c))\n",
    "    for i in range(num_nodes_c):\n",
    "        for j in range(i + 1, num_nodes_c):\n",
    "            weight_c = coh_df.iloc[i, j]\n",
    "            if abs(weight_c) > threshold: \n",
    "                G_filt_c.add_edge(i, j, weight_c=weight_c)\n",
    "    graph_key_c = f\"coherencia espectral_{name.replace(' ', '_').lower()}\"\n",
    "    filtrado_c[graph_key_c] = G_filt_c\n",
    "    print(f\"Created graph '{graph_key_c}' with {G_filt_c.number_of_nodes()} nodes and {G_filt_c.number_of_edges()} edges.\")\n",
    "for graph_key, G_to_draw in filtrado_c.items():\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(G_to_draw) \n",
    "    nx.draw(G_to_draw, pos, with_labels=False, node_size=20, edge_color='gray', alpha=0.6)\n",
    "    plt.title(f'Filtered Graph: {graph_key.replace(\"_\", \" \").title()}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa45eb4-879e-4a30-9f9a-21d257d2b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "plv = sns.heatmap(plv_df.values,\n",
    "                 annot=False, cmap='GnBu', fmt=\".2f\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "val_plv = corr_df.values[np.triu_indices_from(plv_df, k=1)]\n",
    "plt.hist(val_plv, bins=45)\n",
    "p25_p = np.percentile(val_plv, 25)  \n",
    "p50_p = np.percentile(val_plv, 50)  \n",
    "p75_p = np.percentile(val_plv, 75)  \n",
    "print(f\"Percentil 25: {p25_p:.4f}\")\n",
    "print(f\"Percentil 50: {p50_p:.4f}\")\n",
    "print(f\"Percentil 75: {p75_p:.4f}\")\n",
    "percentiles_p = {'25': p25_p, '50': p50_p, '75': p75_p}\n",
    "filtrado_p = {}\n",
    "for name, threshold in percentiles_p.items():\n",
    "    G_filt_p = nx.Graph()\n",
    "    num_nodes_p = coh_df.shape[0]\n",
    "    G_filt_p.add_nodes_from(range(num_nodes_p))\n",
    "\n",
    "    for i in range(num_nodes_p):\n",
    "        for j in range(i + 1, num_nodes_p):\n",
    "            weight_p = plv_df.iloc[i, j]\n",
    "            if abs(weight_p) > threshold: \n",
    "                G_filt_c.add_edge(i, j, weight_p=weight_p)\n",
    "    graph_key_p = f\"phase locking value_{name.replace(' ', '_').lower()}\"\n",
    "    filtrado_p[graph_key_p] = G_filt_p\n",
    "    print(f\"Created graph '{graph_key_p}' with {G_filt_p.number_of_nodes()} nodes and {G_filt_p.number_of_edges()} edges.\")\n",
    "for graph_key, G_to_draw in filtrado_p.items():\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(G_to_draw) \n",
    "    nx.draw(G_to_draw, pos, with_labels=False, node_size=20, edge_color='blue', alpha=0.6)\n",
    "    plt.title(f'Filtered Graph: {graph_key.replace(\"_\", \" \").title()}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c7065-ed9b-4333-b117-34bcff5017fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "coords = datos['Coord'] \n",
    "G_3d = nx.from_numpy_array(data)\n",
    "degrees_3d = dict(G_3d.degree())\n",
    "node_size_factor = 5 \n",
    "node_sizes = [degrees_3d[node] * node_size_factor for node in G_3d.nodes()]\n",
    "edge_weights = np.array([G_3d[u][v]['weight'] for u, v in G_3d.edges()])\n",
    "if np.max(edge_weights) != np.min(edge_weights):\n",
    "    norm_edge_weights = (edge_weights - np.min(edge_weights)) / (np.max(edge_weights) - np.min(edge_weights))\n",
    "else:\n",
    "    norm_edge_weights = np.zeros_like(edge_weights) \n",
    "cmap = cm.get_cmap('hot')\n",
    "edge_colors = cmap(norm_edge_weights)\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "node_xyz = np.array([coords[i] for i in G_3d.nodes()])\n",
    "ax.scatter(node_xyz[:, 0], node_xyz[:, 1], node_xyz[:, 2], s=node_sizes, c='skyblue', alpha=0.8)\n",
    "for i, (u, v) in enumerate(G_3d.edges()):\n",
    "    x = np.array([coords[u, 0], coords[v, 0]])\n",
    "    y = np.array([coords[u, 1], coords[v, 1]])\n",
    "    z = np.array([coords[u, 2], coords[v, 2]])\n",
    "    ax.plot(x, y, z, color=edge_colors[i], alpha=0.5)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.title('3DG Coactivation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022e11c-f925-4b55-b897-5a4853c218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_edf(r\"C:\\Users\\maria\\OneDrive\\Documentos\\MATLAB\\chb01_01.edf\", preload=True)\n",
    "print(raw)\n",
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b4952-db49-433c-b1f0-8d75d5da780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bct\n",
    "eeg_channels = [ch for ch in raw.ch_names if 'EEG' in ch];\n",
    "raw_eeg = raw.copy().pick_channels(eeg_channels, ordered=True);\n",
    "variances = raw_eeg.get_data().var(axis=1);\n",
    "variance_threshold = 1e-10\n",
    "low_variance_channels = [raw_eeg.ch_names[i] for i, var in enumerate(variances) if var < variance_threshold];\n",
    "raw_eeg.drop_channels(low_variance_channels);\n",
    "raw_eeg.set_eeg_reference('average', projection=True);\n",
    "raw_eeg.apply_proj();\n",
    "l_freq, h_freq = 1, 40\n",
    "raw_eeg.filter(l_freq, h_freq, fir_design='firwin');\n",
    "preprocessed_data = raw_eeg.get_data();\n",
    "connectivity_matrix = np.corrcoef(preprocessed_data);\n",
    "connectivity_matrix_df = pd.DataFrame(connectivity_matrix);\n",
    "connectivity_matrix_df.fillna(0, inplace=True);\n",
    "connectivity_matrix_df.replace([np.inf, -np.inf], 0, inplace=True);\n",
    "G_edf = nx.from_numpy_array(connectivity_matrix_df.values);\n",
    "edf_degrees = dict(G_edf.degree())\n",
    "print(\"Grados de nodos:\", edf_degrees)\n",
    "edf_global_efficiency = bct.efficiency_wei(connectivity_matrix_df.values)\n",
    "print(\"Ef global:\", edf_global_efficiency)\n",
    "edf_local_efficiency = bct.efficiency_wei(connectivity_matrix_df.values, local=True)\n",
    "print(\"Ef local:\", edf_local_efficiency)\n",
    "edf_clustering_coefficient = nx.average_clustering(G_edf)\n",
    "print(\"Coef cluster:\", edf_clustering_coefficient)\n",
    "if nx.is_connected(G_edf):\n",
    "    edf_avg_shortest_path_length = nx.average_shortest_path_length(G_edf)\n",
    "    print(\"ruta más corta:\", edf_avg_shortest_path_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41fbe7-698e-4a03-8e1c-262c3ee1efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_edf = G_edf.number_of_nodes()\n",
    "n_edges_edf = G_edf.number_of_edges()\n",
    "G_random_edf = nx.gnm_random_graph(n_nodes_edf, n_edges_edf)\n",
    "clustering_coefficient_random_edf = nx.average_clustering(G_random_edf)\n",
    "print(\"Coef cluster:\", clustering_coefficient_random_edf)\n",
    "if nx.is_connected(G_random_edf):\n",
    "    avg_shortest_path_length_random_edf = nx.average_shortest_path_length(G_random_edf)\n",
    "    print(\"Ruta más corta:\", avg_shortest_path_length_random_edf)\n",
    "if avg_shortest_path_length_random_edf > 0 and edf_avg_shortest_path_length > 0 and clustering_coefficient_random_edf > 0:\n",
    "    small_world_coefficient_edf = (edf_clustering_coefficient / clustering_coefficient_random_edf) / (edf_avg_shortest_path_length / avg_shortest_path_length_random_edf)\n",
    "    print(\"Coef mundo pequeño:\", small_world_coefficient_edf)\n",
    "\n",
    "import community.community_louvain as community_louvain\n",
    "G_edf_abs = nx.from_numpy_array(np.abs(connectivity_matrix_df.values))\n",
    "edf_partition = community_louvain.best_partition(G_edf_abs)\n",
    "print(\"comunidades:\", edf_partition)\n",
    "edf_degrees_abs = dict(G_edf_abs.degree())\n",
    "edf_avg_degree_abs = np.mean(list(edf_degrees_abs.values()))\n",
    "edf_hubs_abs = [node for node, degree in edf_degrees_abs.items() if degree > edf_avg_degree_abs]\n",
    "print(\"Hubs\", edf_hubs_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58bb24-613f-47d0-b199-49c6de971211",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = G_edf.number_of_nodes()\n",
    "np.random.seed(42) \n",
    "coords_edf = np.random.rand(num_nodes, 3) * 10 \n",
    "edf_degrees = dict(G_edf.degree())\n",
    "node_size_factor = 50 \n",
    "node_sizes_edf = [edf_degrees[node] * node_size_factor for node in G_edf.nodes()]\n",
    "edge_weights_edf = np.array([G_edf[u][v]['weight'] for u, v in G_edf.edges()])\n",
    "abs_edge_weights_edf = np.abs(edge_weights_edf)\n",
    "if np.max(abs_edge_weights_edf) != np.min(abs_edge_weights_edf):\n",
    "    norm_edge_colors_edf = (abs_edge_weights_edf - np.min(abs_edge_weights_edf)) / (np.max(abs_edge_weights_edf) - np.min(abs_edge_weights_edf))\n",
    "else:\n",
    "    norm_edge_colors_edf = np.zeros_like(abs_edge_weights_edf) # All weights are the same, use one color\n",
    "cmap = cm.get_cmap('hot')\n",
    "edge_colors_edf = cmap(norm_edge_colors_edf)\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "node_xyz_edf = coords_edf\n",
    "ax.scatter(node_xyz_edf[:, 0], node_xyz_edf[:, 1], node_xyz_edf[:, 2], s=node_sizes_edf, c='skyblue', alpha=0.8)\n",
    "for i, (u, v) in enumerate(G_edf.edges()):\n",
    "    x = np.array([coords_edf[u, 0], coords_edf[v, 0]])\n",
    "    y = np.array([coords_edf[u, 1], coords_edf[v, 1]])\n",
    "    z = np.array([coords_edf[u, 2], coords_edf[v, 2]])\n",
    "    ax.plot(x, y, z, color=edge_colors_edf[i], alpha=0.5)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.title('3DG EDF Connectivity Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad273c68-16d3-4a64-ba75-5c3c0cd78ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
