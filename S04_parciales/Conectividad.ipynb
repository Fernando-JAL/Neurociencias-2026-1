{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a253ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de bivliotecas \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.signal import coherence, butter, filtfilt, hilbert\n",
    "from itertools import combinations\n",
    "from networkx.algorithms import community\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc5eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantiza que los resultados aleatorios (por ejemplo el grafico spring_layout) sean reproducibles.\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a92127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de bandas de frecuencia EEG\n",
    "BANDS = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 13),\n",
    "    \"beta\": (13, 30),\n",
    "    \"gamma\": (30, 45)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981a09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpeta si no existe\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7dc505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar el CSV automáticamente\n",
    "def load_csv_detect(data_path):\n",
    "    df = pd.read_csv(data_path, index_col=None)\n",
    "\n",
    "    # Caso 1: filas = canales\n",
    "    if df.shape[0] < df.shape[1]:\n",
    "        data = df.to_numpy(dtype=float)\n",
    "        ch_names = list(df.index.astype(str))\n",
    "\n",
    "        if df.dtypes[0] == object:\n",
    "            try:\n",
    "                names = df.iloc[:,0].astype(str).values\n",
    "                data = df.iloc[:,1:].to_numpy(dtype=float)\n",
    "                ch_names = list(names)\n",
    "            except:\n",
    "                ch_names = [f\"Ch{i}\" for i in range(data.shape[0])]\n",
    "    else:\n",
    "        # Caso 2: filas = muestras → transponer\n",
    "        if all(np.issubdtype(dt, np.number) for dt in df.dtypes):\n",
    "            data = df.to_numpy(dtype=float).T\n",
    "            ch_names = list(df.columns.astype(str))\n",
    "        else:\n",
    "            data = df.select_dtypes(include=[np.number]).to_numpy(dtype=float).T\n",
    "            ch_names = list(df.select_dtypes(include=[np.number]).columns.astype(str))\n",
    "\n",
    "    return {\"data\": data, \"ch_names\": ch_names}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a917c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro \n",
    "def load_csv_detect(data_path):\n",
    "    df = pd.read_csv(data_path, index_col=None)\n",
    "\n",
    "    # Caso 1: filas = canales\n",
    "    if df.shape[0] < df.shape[1]:\n",
    "        data = df.to_numpy(dtype=float)\n",
    "        ch_names = list(df.index.astype(str))\n",
    "\n",
    "        if df.dtypes[0] == object:\n",
    "            try:\n",
    "                names = df.iloc[:,0].astype(str).values\n",
    "                data = df.iloc[:,1:].to_numpy(dtype=float)\n",
    "                ch_names = list(names)\n",
    "            except:\n",
    "                ch_names = [f\"Ch{i}\" for i in range(data.shape[0])]\n",
    "    else:\n",
    "        # Caso 2: filas = muestras → transponer\n",
    "        if all(np.issubdtype(dt, np.number) for dt in df.dtypes):\n",
    "            data = df.to_numpy(dtype=float).T\n",
    "            ch_names = list(df.columns.astype(str))\n",
    "        else:\n",
    "            data = df.select_dtypes(include=[np.number]).to_numpy(dtype=float).T\n",
    "            ch_names = list(df.select_dtypes(include=[np.number]).columns.astype(str))\n",
    "\n",
    "    return {\"data\": data, \"ch_names\": ch_names}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7a27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de coherencia\n",
    "\n",
    "def compute_coherence_matrix(data, fs, fmin, fmax, nperseg=None):\n",
    "    n_channels = data.shape[0]\n",
    "    nperseg = nperseg or int(fs*2)\n",
    "\n",
    "    coh = np.zeros((n_channels, n_channels))\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        for j in range(i, n_channels):\n",
    "            f, Cxy = coherence(data[i], data[j], fs=fs, nperseg=nperseg)\n",
    "            mask = (f >= fmin) & (f <= fmax)\n",
    "            coh[i, j] = np.mean(Cxy[mask]) if mask.any() else np.mean(Cxy)\n",
    "            coh[j, i] = coh[i, j]\n",
    "\n",
    "    np.fill_diagonal(coh, 0)\n",
    "    return coh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895d44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz PLV\n",
    "def compute_plv_matrix(data):\n",
    "    analytic = hilbert(data, axis=1)\n",
    "    phases = np.angle(analytic)\n",
    "    n_channels = phases.shape[0]\n",
    "\n",
    "    plv = np.zeros((n_channels, n_channels))\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        for j in range(i+1, n_channels):\n",
    "            phase_diff = phases[i] - phases[j]\n",
    "            val = np.abs(np.mean(np.exp(1j*phase_diff)))\n",
    "            plv[i,j] = val\n",
    "            plv[j,i] = val\n",
    "\n",
    "    np.fill_diagonal(plv, 0)\n",
    "    return plv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af77b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral (threshold)\n",
    "\n",
    "def threshold_matrix(mat, percentile=75):\n",
    "    vals = mat.flatten()\n",
    "    vals = vals[~np.isnan(vals)]\n",
    "    th = np.percentile(vals, percentile)\n",
    "\n",
    "    mat_bin = (mat >= th).astype(int)\n",
    "    mat_thresh = mat.copy()\n",
    "    mat_thresh[mat < th] = 0\n",
    "\n",
    "    return mat_thresh, mat_bin, th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0491214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas del grafo\n",
    "def graph_metrics_from_adj(adj):\n",
    "    G = nx.from_numpy_array(adj)\n",
    "\n",
    "    deg = dict(G.degree(weight='weight'))\n",
    "    betw = nx.betweenness_centrality(G)\n",
    "    clust = nx.clustering(G, weight='weight') if len(G) > 0 else {}\n",
    "\n",
    "    try:\n",
    "        comms = list(community.greedy_modularity_communities(G))\n",
    "        modularity = nx.community.modularity(G, comms)\n",
    "    except:\n",
    "        comms, modularity = [], None\n",
    "\n",
    "    return {\n",
    "        \"graph\": G,\n",
    "        \"degree\": deg,\n",
    "        \"betweenness\": betw,\n",
    "        \"clustering\": clust,\n",
    "        \"communities\": comms,\n",
    "        \"modularity\": modularity\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f137cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar heatmap\n",
    "def plot_heatmap(mat, ch_names, title, outpath):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    df = pd.DataFrame(mat, index=ch_names, columns=ch_names)\n",
    "    plt.imshow(df, aspect='equal')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06803992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar grafo en 2D\n",
    "def plot_graph_2d(G, ch_names, outpath, node_size_map=None):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    pos = nx.spring_layout(G, seed=RANDOM_SEED)\n",
    "\n",
    "    node_sizes = [node_size_map.get(i, 100) for i in range(len(G.nodes()))] if node_size_map else 100\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, labels={i: ch_names[i] for i in range(len(ch_names))},\n",
    "            node_size=node_sizes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9d0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejecuta todo el proceso de análisis EEG de inicio a fin.\n",
    "def run_pipeline_jupyter(\n",
    "    data_path,\n",
    "    fs=256,\n",
    "    method=\"coherence\",\n",
    "    band=\"alpha\",\n",
    "    outdir=\"./outputs_jupyter\",\n",
    "    threshold_percentile=75\n",
    "):\n",
    "\n",
    "    print(\"Cargando archivo…\")\n",
    "    info = load_csv_detect(data_path)\n",
    "\n",
    "    data_arr = info[\"data\"]\n",
    "    ch_names = info[\"ch_names\"]\n",
    "\n",
    "    ensure_dir(outdir)\n",
    "\n",
    "    print(\"Aplicando filtro banda…\")\n",
    "    fmin, fmax = BANDS[band]\n",
    "    data_bp = bandpass(data_arr, fs, fmin, fmax)\n",
    "\n",
    "    print(\"Calculando conectividad…\")\n",
    "    if method == \"coherence\":\n",
    "        conn = compute_coherence_matrix(data_bp, fs, fmin, fmax)\n",
    "    else:\n",
    "        conn = compute_plv_matrix(data_bp)\n",
    "\n",
    "    plot_heatmap(conn, ch_names, f\"Conectividad {method}\", f\"{outdir}/heatmap_continuous.png\")\n",
    "\n",
    "    print(\"Aplicando threshold…\")\n",
    "    conn_thresh, conn_bin, th = threshold_matrix(conn, percentile=threshold_percentile)\n",
    "\n",
    "    plot_heatmap(conn_thresh, ch_names, \"Thresholded\", f\"{outdir}/heatmap_thresholded.png\")\n",
    "\n",
    "    print(\"Calculando métricas…\")\n",
    "    metrics = graph_metrics_from_adj(conn_thresh)\n",
    "\n",
    "    degree = metrics[\"degree\"]\n",
    "    node_size_map = {i: (degree[i]+1)*80 for i in degree}\n",
    "\n",
    "    plot_graph_2d(metrics[\"graph\"], ch_names, f\"{outdir}/graph2d.png\", node_size_map=node_size_map)\n",
    "\n",
    "    pd.DataFrame(conn_thresh, index=ch_names, columns=ch_names).to_csv(f\"{outdir}/adjacency_thresholded.csv\")\n",
    "    pd.DataFrame(conn, index=ch_names, columns=ch_names).to_csv(f\"{outdir}/adjacency_continuous.csv\")\n",
    "\n",
    "    with open(f\"{outdir}/metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    print(\"Pipeline completado. Resultados guardados en:\", outdir)\n",
    "\n",
    "    return metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
