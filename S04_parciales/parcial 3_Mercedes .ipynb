{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dfb6a8-6b17-4186-9ef7-1232a3eba8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#cargar módulo\n",
    "from mi_modulo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc76ee7-09d5-49f1-9980-5b8ff43fbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensayo3_excel = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_03.xlsx\"\n",
    "ensayo4_excel = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_04.xlsx\"\n",
    "coordenadas_csv = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\MI_coordinates.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc6e54b-6aea-4708-a7c1-e4792f5c9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensayo3_dict = pd.read_excel(ensayo3_excel, sheet_name=None, index_col=0)\n",
    "ensayo4_dict = pd.read_excel(ensayo4_excel, sheet_name=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1933c8fd-e8ab-48b0-a7a0-16deec6c1955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensayo3_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ensayos3_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mlista_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensayo3_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m ensayos4_dfs \u001b[38;5;241m=\u001b[39m lista_dfs(ensayo4_dict)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Neurociencias-2026-1\\S04_parciales\\mi_modulo.py:10\u001b[0m, in \u001b[0;36mlista_dfs\u001b[1;34m(ensayo_dict)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlista_dfs\u001b[39m(ensayo_dict):\n\u001b[0;32m      9\u001b[0m     ensayos_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sujeto \u001b[38;5;129;01min\u001b[39;00m \u001b[43mensayo3_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     11\u001b[0m         ensayos_dfs\u001b[38;5;241m.\u001b[39mappend(ensayo3_dict[sujeto])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensayos_dfs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ensayo3_dict' is not defined"
     ]
    }
   ],
   "source": [
    "ensayos3_dfs = lista_dfs(ensayo3_dict)\n",
    "ensayos4_dfs = lista_dfs(ensayo4_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8970c78-bb12-4e89-ac92-a339e29d584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados3_dfs =lista_dfs(ensayo3_dict)\n",
    "resultado3_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd1089-0274-4639-a3d3-80a41d375258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado de matrices\n",
    "def capsula(lista_dfs, th, porcentaje_):\n",
    "    # Conjuntamos las matrices\n",
    "    stack = np.stack([df.values for df in lista_dfs])\n",
    "    # Aplicamos filtro a cada matriz\n",
    "    above = stack > th\n",
    "    \n",
    "    N = len(lista_dfs) # = 109\n",
    "    count_above = above.sum(axis=0) # Contando cuantos valores superan el umbral en celda\n",
    "    \n",
    "    min_requerido = int(np.ceil(porcentaje_*N)) # 0.6*109 = 65.4\n",
    "    # con esto bastara con quedarnos con las celdas de 'above' que cumplan con min_requerido\n",
    "    # para así tener el número de sujetos que superan el umbral\n",
    "    result_bool = count_above >= min_requerido\n",
    "    \n",
    "    result_df = pd.DataFrame(result_bool, \n",
    "                             index=lista_dfs[0].index, \n",
    "                             columns=lista_dfs[0].columns).astype(int)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7bc68-6a10-4934-b07f-120ea27ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_df = capsula(ensayos_dfs, 0.5, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e078c-4d68-4ec3-8217-4c0a12b0f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "sns.heatmap(resultado_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c4d2a-a1d6-4f7d-a690-cfc77b3a9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensayos_dfs\n",
    "\n",
    "th25, th50, th75, promedio, varianza = [], [], [], [], []\n",
    "mu_sigma = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7))\n",
    "for sujeto in ensayos_dfs:\n",
    "    # Calculo de estadísticos\n",
    "    data = sujeto.stack().values\n",
    "    th25.append(np.percentile(data, 25))\n",
    "    th50.append(np.percentile(data, 50))\n",
    "    th75.append(np.percentile(data, 75))\n",
    "    promedio.append(np.mean(data))\n",
    "    varianza.append(np.var(data))\n",
    "    mu_sigma.append(np.mean(data) + np.var(data))\n",
    "    # Plots\n",
    "    sns.histplot(sujeto.stack().values, ax=axes[0][0], kde=True)\n",
    "    sns.ecdfplot(sujeto.stack().values, ax=axes[0][1])\n",
    "axes[1][0].plot(th25, label='Percentil al 25%')\n",
    "axes[1][0].plot(th50, label='Percentil al 50%')\n",
    "axes[1][0].plot(th75, label='Percentil al 75%')\n",
    "axes[1][0].plot(promedio, label='Media')\n",
    "axes[1][0].plot(varianza, label='Varianza')\n",
    "axes[1][0].plot(mu_sigma, label='mu+sigma')\n",
    "axes[1][0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e3d64-b231-490c-acc5-a43ff097c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.median_abs_deviation(th25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b737f0-9640-4118-8d52-2874489e40e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticos_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'], \n",
    "                               index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "columnas = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "min_, max_, mediana_, cosa_ = [], [], [], []\n",
    "for columna in columnas:\n",
    "    d1, d2, d3, d4 = np.min(columna), np.max(columna), np.median(columna), stats.median_abs_deviation(columna)\n",
    "    min_.append(d1)\n",
    "    max_.append(d2)\n",
    "    mediana_.append(d3)\n",
    "    cosa_.append(d4)\n",
    "estadisticos_df.loc['min'] = min_\n",
    "estadisticos_df.loc['max'] = max_\n",
    "estadisticos_df.loc['mediana'] = mediana_\n",
    "estadisticos_df.loc['cosa_rara'] = cosa_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e18548-306e-44c6-9b8f-9621cdaad059",
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticos_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'], \n",
    "                               index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "\n",
    "columnas = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "min_, max_, mediana_, cosa_ = [], [], [], []\n",
    "for idx, columna in enumerate(estadisticos_df.columns):\n",
    "    d1, d2, d3, d4 = np.min(columnas[idx]), np.max(columnas[idx]), np.median(columnas[idx]), stats.median_abs_deviation(columnas[idx])\n",
    "    estadisticos_df[columna] = [d1, d2, d3, d4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d177554-b301-4b8c-804a-5f5f0a151d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qué variables vamos a ir cambiando? --> threshold, porcentaje, ensayo\n",
    "\n",
    "def capsula(lista_dfs, th, porcentaje_):\n",
    "    # conjuntamos las matrices\n",
    "    stack = np.stack([df.values for df in lista_dfs])\n",
    "\n",
    "    # aplicamos el filtro a cada matriz\n",
    "    above = stack > th\n",
    "\n",
    "    N = len(lista_dfs)\n",
    "    count_above = above.sum(axis = 0)  # contar cuántos valores superan el umbral en celda\n",
    "\n",
    "    min_requerido = int(np.ceil(porcentaje_*N)) # np.ceil redondea para arriba\n",
    "    # con esto bastará con quedarnos con las celdas de \"above\" que cumplan con min_requerido, para así tener el número de sujetos que superan el umbral\n",
    "    \n",
    "    # Vamos a obtener a la matriz binarizada de todos\n",
    "    result_bool = count_above >= min_requerido\n",
    "\n",
    "    result_df = pd.DataFrame(result_bool, index=lista_dfs[0].index, columns=lista_dfs[0].columns)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cdab0-db30-4765-b529-d8c65291fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_df = capsula(ensayos_dfs, 0.5, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe842e8-6d90-472e-a01e-0a0660d760bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 3))\n",
    "\n",
    "sns.heatmap(resultado_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3868be-eb22-42ce-b6c8-246a7fc65c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['th25', 'th50', 'th75', 'promedio', 'mu_sigma'], \n",
    "                               index=['min', 'max', 'mediana', 'cosa_rara'])\n",
    "estadisticos_ = [th25, th50, th75, promedio, mu_sigma]\n",
    "\n",
    "for idx, columna in enumerate(test_df.columns):\n",
    "    test_df[columna] = [np.min(estadisticos_[idx]), np.min(estadisticos_[idx]), \n",
    "                        np.median(min(estadisticos_[idx])), stats.median_abs_deviation(estadisticos_[idx])]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4462c4-e09d-4af5-a14b-35d004804b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_df1 = capsula(ensayos_dfs, 0.2, 0.6)\n",
    "resultado_df2 = capsula(ensayos_dfs, 0.3, 0.6)\n",
    "resultado_df3 = capsula(ensayos_dfs, 0.5, 0.6)\n",
    "resultado_df4 = capsula(ensayos_dfs, 0.6, 0.6)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 5))\n",
    "\n",
    "sns.heatmap(resultado_df1, ax=axes[0, 0])\n",
    "sns.heatmap(resultado_df2, ax=axes[0, 1])\n",
    "sns.heatmap(resultado_df3, ax=axes[1, 0])\n",
    "sns.heatmap(resultado_df4, ax=axes[1, 1])\n",
    "# plt.title('Mapas de calor para comparativa de umbrales')\n",
    "axes[0, 0].set_title('umbral=0.2, poblacion>60%', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a5d18-6780-4a93-b03e-8ce665195b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_df1 = capsula(ensayos_dfs, 0.3, 0.5)\n",
    "resultado_df2 = capsula(ensayos_dfs, 0.3, 0.6)\n",
    "resultado_df3 = capsula(ensayos_dfs, 0.3, 0.7)\n",
    "resultado_df4 = capsula(ensayos_dfs, 0.3, 0.8)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 5))\n",
    "\n",
    "sns.heatmap(resultado_df1, ax=axes[0, 0])\n",
    "sns.heatmap(resultado_df2, ax=axes[0, 1])\n",
    "sns.heatmap(resultado_df3, ax=axes[1, 0])\n",
    "sns.heatmap(resultado_df4, ax=axes[1, 1])\n",
    "# plt.title('Mapas de calor para comparativa de umbrales')\n",
    "axes[0, 0].set_title('umbral=0.3, poblacion>50%', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957cabb0-7467-4d3a-b1e2-13d79402ccd5",
   "metadata": {},
   "source": [
    "Generación de resultados\n",
    "Después del análisis realizado, utilizando los mapas de calor, para poder escoger un threshold adecuado y un porcentaje de la población que cumpla dicho umbral; se procederá a generar los resultados.\n",
    "\n",
    "Resultados a generar:\n",
    "\n",
    "Grafo2D\n",
    "Grafo3D\n",
    "Métricas de grafo\n",
    "Gráfico de comunidades con Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8217734-70e4-40eb-a44b-2f3edc07e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafo 2D\n",
    "ensayo_grafo = nx.from_pandas_adjacency(resultado_df4)\n",
    "nx.draw_circular(ensayo_grafo, with_labels=True, font_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdfa83-35e0-4310-88fc-75c4b1d11434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_grafo(G):\n",
    "    # Métricas:\n",
    "    #Clusterin promedio\n",
    "    clust_coeff = nx.average_clustering(G)\n",
    "    # Longitud de camino promedio (camino más corto)\n",
    "    try:\n",
    "        path_length = nx.average_shortest_path_length(G)\n",
    "    except nx.NetworkXError:\n",
    "        path_length = np.nan # red no conexa\n",
    "    # Coeficiente de mundo pequeño\n",
    "    # Comparar con grafo aleatorio de igual N, K\n",
    "    G_rand = nx.gnm_random_graph(n=G.number_of_nodes(), m=G.number_of_edges())\n",
    "    clust_rand = nx.average_clustering(G_rand)\n",
    "    path_rand = nx.average_shortest_path_length(G_rand)\n",
    "    small_world_sigma = (clust_coeff / clust_rand) / (path_length / path_rand)\n",
    "    # Modularidad\n",
    "    from networkx.algorithms import community\n",
    "    communities = community.greedy_modularity_communities(G)\n",
    "    modularity = community.modularity(G, communities)\n",
    "    # Hubs\n",
    "    degree_dict = dict(G.degree())\n",
    "    betwenness = nx.betweenness_centrality(G)\n",
    "    betwenness = sorted(betwenness.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Eficiencia global y local\n",
    "    global_eff = nx.global_efficiency(G)\n",
    "    local_eff = nx.local_efficiency(G)\n",
    "\n",
    "    return (clust_coeff, path_length, small_world_sigma, communities, \n",
    "            modularity, betwenness, global_eff, local_eff, degree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b028a-28f1-4ed5-9780-ceda6de9e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(clust_coeff_, path_length_, small_world_sigma_, communities_, \n",
    " modularity_, betwenness_, global_eff_, local_eff_, degree_dict_) = metricas_grafo(ensayo_grafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889ed64-2700-4541-918a-fdf48ed71d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir de dataframe a grafo\n",
    "ensayo3_grafo_ = nx.from_pandas_adjacency(resultado3_df3)\n",
    "ensayo4_grafo_ = nx.from_pandas_adjacency(resultado4_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b37930-a66f-410a-900e-bd46409cd9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construcción de dataframe de coordenadas\n",
    "eeg_coords = pd.read_csv(coordenadas_csv)\n",
    "eeg_coords.set_index(\"canal\", drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b84ce9-44b7-4976-804e-f02f4667100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = eeg_coords['x'].values, eeg_coords['y'].values, eeg_coords['z'].values\n",
    "hub = betwenness_[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "axes = [fig.add_subplot(1, 1, 1, projection='3d')]\n",
    "\n",
    "nodes_size = [30 if idx != hub[0] else 200 for idx in eeg_coords.index]\n",
    "axes[0].scatter(x, y, z, alpha=0.5, s=nodes_size)\n",
    "for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "    axes[0].text(x_, y_, z_, eeg_coords.index[idx], fontsize=10)\n",
    "    if eeg_coords.index[idx] == hub[0]:\n",
    "        axes[0].text(x_, y_, z_, 'HUB', color='red', fontweight='bold', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852a94d-7a97-4a89-9ca9-27690c9b489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregamos _ a las variables para que las variables globales y locales tengan nombres diferentes\n",
    "\n",
    "(clust_coeff_3, path_length_3, small_world_sigma_3, communities_3, \n",
    " modularity_3, betwenness_3, global_eff_3, local_eff_3, degree_dict_3) = metricas_grafo(ensayo3_grafo_)\n",
    "\n",
    "(clust_coeff_4, path_length_4, small_world_sigma_4, communities_4, \n",
    " modularity_4, betwenness_4, global_eff_4, local_eff_4, degree_dict_4) = metricas_grafo(ensayo4_grafo_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e36d3e-c027-4cd4-a053-4d9ab9818345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 3D\n",
    "\n",
    "# construir dataframe de coordenadas\n",
    "eeg_coords = pd.read_csv(coordenadas_csv)\n",
    "eeg_coords.set_index(\"canal\", drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fad45-3d84-482e-89ef-86e1ad9c61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_coords.loc[\"Fc5.\", \"y\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697fc75-f0ac-458f-89fb-ca1d0d6c0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = eeg_coords[\"x\"].values, eeg_coords[\"y\"].values, eeg_coords[\"z\"].values\n",
    "hub = betwenness_[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "axes = [fig.add_subplot(1, 1, 1, projection = \"3d\")]\n",
    "\n",
    "nodes_size = [30 if idx != hub[0] else 200 for idx in eeg_coords.index] # cambiar el tamaño del nodo si es el hub\n",
    "axes[0].scatter(x, y, z, alpha = 0.5)\n",
    " \n",
    "for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "    axes[0].text(x_, y_, z_, eeg_coords.index[idx], fontsize = 10)\n",
    "    if eeg_coords.index[idx] == hub[0]:\n",
    "        axes[0].text(x_, y_, z_, \"HUB\", color = \"red\", fontsize = 13) # cambiar el color del texto del nodo si es el hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c915cd-4ba2-4e62-b715-a7bf54e925af",
   "metadata": {},
   "outputs": [],
   "source": [
    "podemos generar un grafo de comunidades, lo podemos encapsular en una línea y aplicarlo a más ensayos.\n",
    "Poder hacer comparaciones entre ensayos\n",
    "generar el for sobre las comunidades en vez de los nodos para hacer las comparaciones entre comunidades\n",
    "Grafo de comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bd019-9c20-4cd7-bc47-6e9a7a3099de",
   "metadata": {},
   "outputs": [],
   "source": [
    "comunidad_prueba = communities_[2]   # objeto frozenset, no es iterable, lo debemos cambiar\n",
    "n1, n2 = list(comunidad_prueba)[0], list(comunidad_prueba)[1] # en casos de que solo tengamos un par de nodos, si tenemos más nodos debemos ir recorriendolo por pares\n",
    "n1, n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6d050-a434-49c8-a775-1dc29e7464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafo de comunidades\n",
    "\n",
    "x, y, z = eeg_coords[\"x\"].values, eeg_coords[\"y\"].values, eeg_coords[\"z\"].values\n",
    "hub = betwenness_[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "axes = [fig.add_subplot(1, 1, 1, projection = \"3d\")]\n",
    "\n",
    "nodes_size = [30 if idx != hub[0] else 200 for idx in eeg_coords.index] # cambiar el tamaño del nodo si es el hub\n",
    "axes[0].scatter(x, y, z, alpha = 0.5)\n",
    " \n",
    "for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "    axes[0].text(x_, y_, z_, eeg_coords.index[idx], fontsize = 10)\n",
    "    if eeg_coords.index[idx] == hub[0]:\n",
    "        axes[0].text(x_, y_, z_, \"HUB\", color = \"red\", fontsize = 13) # cambiar el color del texto del nodo si es el hub\n",
    "\n",
    "colores = [\"yellow\", \"blue\", \"orange\", \"olive\", \"red\"]\n",
    "for n_comunidad, comunidad in enumerate(communities_):  # recorrer las comunidades, plotearemos así las aristas\n",
    "    for idx in range(len(comunidad)-1):\n",
    "        n1, n2 = list(comunidad)[idx], list(comunidad)[idx+1]\n",
    "        # plotear arista\n",
    "        x_ = [eeg_coords.loc[n1, \"x\"], eeg_coords.loc[n2, \"x\"]]\n",
    "        y_ = [eeg_coords.loc[n1, \"y\"], eeg_coords.loc[n2, \"y\"]]\n",
    "        z_ = [eeg_coords.loc[n1, \"z\"], eeg_coords.loc[n2, \"z\"]]\n",
    "        axes[0].plot(x_, y_, z_, linewidth = 3, alpha = 0.4, color = colores[n_comunidad])\n",
    "axes[0].set_title(\"comunidades del ensayo 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba740c5-2737-436f-9a7f-6e15ee2e6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulación gráficos de comunidades\n",
    "\n",
    "def grafo_comunidades(comunidades, Hub, coords, pos):\n",
    "    x, y, z = coords[\"x\"].values, coords[\"y\"].values, coords[\"z\"].values\n",
    "\n",
    "    nodes_size = [30 if idx != Hub[0] else 200 for idx in coords.index] # cambiar el tamaño del nodo si es el hub\n",
    "    pos.scatter(x, y, z, alpha = 0.5)\n",
    " \n",
    "    for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "        pos.text(x_, y_, z_, coords.index[idx], fontsize = 10)\n",
    "        if coords.index[idx] == Hub[0]:\n",
    "            pos.text(x_, y_, z_, \"HUB\", color = \"red\", fontsize = 13) # cambiar el color del texto del nodo si es el hub\n",
    "\n",
    "    colores = [\"yellow\", \"blue\", \"orange\", \"olive\", \"red\"]\n",
    "    for n_comunidad, comunidad in enumerate(comunidades):  # recorrer las comunidades, plotearemos así las aristas\n",
    "        for idx in range(len(comunidad)-1):\n",
    "            n1, n2 = list(comunidad)[idx], list(comunidad)[idx+1]\n",
    "            # plotear arista\n",
    "            x_ = [coords.loc[n1, \"x\"], coords.loc[n2, \"x\"]]\n",
    "            y_ = [coords.loc[n1, \"y\"], coords.loc[n2, \"y\"]]\n",
    "            z_ = [coords.loc[n1, \"z\"], coords.loc[n2, \"z\"]]\n",
    "            pos.plot(x_, y_, z_, linewidth = 3, alpha = 0.4, color = colores[n_comunidad])\n",
    "    pos.set_title(\"comunidades del ensayo 3\")\n",
    "\n",
    "\n",
    "hub = betwenness_[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "axes = [fig.add_subplot(1, 1, 1, projection = \"3d\")]\n",
    "grafo_comunidades(communities_, hub, eeg_coords, axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602a424-5edb-47ba-bfc9-35de83ff7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafo_3d(Hub, coords, pos):\n",
    "    x, y, z =coords[\"x\"].values, coords[\"y\"].values, coords[\"z\"].values\n",
    "    \n",
    "    nodes_size = [30 if idx != Hub[0] else 200 for idx in coords.index] # cambiar el tamaño del nodo si es el hub\n",
    "    pos.scatter(x, y, z, alpha = 0.5)\n",
    "     \n",
    "    for idx, (x_, y_, z_) in enumerate(zip(x, y, z)):\n",
    "        pos.text(x_, y_, z_, coords.index[idx], fontsize = 10)\n",
    "        if coords.index[idx] == hub[0]:\n",
    "            pos.text(x_, y_, z_, \"HUB\", color = \"red\", fontsize = 13) # cambiar el color del texto del nodo si es el \n",
    "\n",
    "hub = betwenness_[0]\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "axes = [fig.add_subplot(1, 1, 1, projection = \"3d\")]\n",
    "grafo_3d(hub, eeg_coords, axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27945a-e1fd-4d2c-b599-d4b1a2f9e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafo_2d(ensayo_df, pos):\n",
    "    ensayo_grafo_ = nx.from_pandas_adjacency(ensayo_df)\n",
    "    nx.draw_circular(ensayo_grafo, with_labels = True, font_size = 7.5, ax = pos)\n",
    "    return ensayo_grafo_\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "axes = [fig.add_subplot(1, 2, 1)]\n",
    "\n",
    "grafo_2d(resultado_df4, axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f21df-5e24-43fc-9c3e-3d72834feea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = betwenness_3[0]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "axes = [fig.add_subplot(2, 2, 1, projection = \"3d\"),\n",
    "       fig.add_subplot(2, 2, 2, projection = \"3d\"),\n",
    "       fig.add_subplot(2,2,3)]\n",
    "\n",
    "grafo_comunidades(communities_3, hub, eeg_coords, axes[0])\n",
    "grafo_3d(hub, eeg_coords, axes[1])\n",
    "ensayo_grafo = grafo_2d(resultado3_df4, axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bc61e-d187-41a4-aaf5-d109353c3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = betwenness_4[0]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "axes = [fig.add_subplot(2, 2, 1, projection = \"3d\"),\n",
    "       fig.add_subplot(2, 2, 2, projection = \"3d\"),\n",
    "       fig.add_subplot(2,2,3)]\n",
    "\n",
    "grafo_comunidades(communities_4, hub, eeg_coords, axes[0])\n",
    "grafo_3d(hub, eeg_coords, axes[1])\n",
    "ensayo_grafo = grafo_2d(resultado4_df4, axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104f6d0-075e-4256-8267-e5d2c7e6c682",
   "metadata": {},
   "source": [
    "# Ensayo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c362a20-5611-436c-abee-4fcce813f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "ensayo5_excel = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_03.xlsx\"\n",
    "ensayo6_excel = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\eeg-motor-movementimagery_Ensayo_04.xlsx\"\n",
    "coordenadas_csv = r\"C:\\Users\\ecere\\Documents\\GitHub\\Neurociencias-2026-1\\S03_datasets\\MI_coordinates.csv\"\n",
    "\n",
    "ensayo5_dict = pd.read_excel(ensayo5_excel, sheet_name=None, index_col=0)\n",
    "ensayo6_dict = pd.read_excel(ensayo6_excel, sheet_name=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9594182-ca20-4f18-a84d-d1cd087da664",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensayo3_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ensayos5_dfs \u001b[38;5;241m=\u001b[39m \u001b[43mlista_dfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensayo5_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m ensayos6_dfs \u001b[38;5;241m=\u001b[39m lista_dfs(ensayo6_dict)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Neurociencias-2026-1\\S04_parciales\\mi_modulo.py:10\u001b[0m, in \u001b[0;36mlista_dfs\u001b[1;34m(ensayo_dict)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlista_dfs\u001b[39m(ensayo_dict):\n\u001b[0;32m      9\u001b[0m     ensayos_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sujeto \u001b[38;5;129;01min\u001b[39;00m \u001b[43mensayo3_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     11\u001b[0m         ensayos_dfs\u001b[38;5;241m.\u001b[39mappend(ensayo3_dict[sujeto])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensayos_dfs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ensayo3_dict' is not defined"
     ]
    }
   ],
   "source": [
    "ensayos5_dfs = lista_dfs(ensayo5_dict)\n",
    "ensayos6_dfs = lista_dfs(ensayo6_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caebb7c2-15f9-40a8-bee4-c3f6840e41a6",
   "metadata": {},
   "source": [
    "# Ensayo 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
